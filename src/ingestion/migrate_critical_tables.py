#!/usr/bin/env python3
"""
Migrate Critical Tables
Targeted migration for the discovered critical eyecare tables
"""

import os
import sys
import pandas as pd
from pathlib import Path
from dotenv import load_dotenv
from rich.console import Console
from rich.table import Table
from rich.panel import Panel
from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn
import snowflake.connector
from sqlalchemy import create_engine, text

# Add project root to path
project_root = Path(__file__).parent.parent.parent
sys.path.append(str(project_root))

# Load environment variables
load_dotenv(project_root / ".env")

console = Console()

class CriticalTableMigration:
    """Migrate critical tables with correct names"""
    
    def __init__(self):
        """Initialize critical table migration"""
        # Critical tables with correct names discovered
        self.critical_tables = {
            'InvoiceDetail': 'InvoiceDetail',  # Exact match found
            'OrderItem': 'ItemOrder',  # Alternative found
            'BillingClaimDetail': 'BillingClaimChangeDetail',  # Alternative found
            'AppSchedule': 'AppSch_Appointment',  # Alternative found
            # Additional critical tables discovered
            'BillingClaimLineItem': 'BillingClaimLineItem',  # Found in discovery
            'AppSch_Appointment_History': 'AppSch_Appointment_History',  # Found in discovery
            'Appointment': 'Appointment',  # Found in discovery
            'BillingClaimData': 'BillingClaimData'  # Found in discovery
        }
        
        # Source connection
        self.source_conn_str = f"mssql+pymssql://{os.getenv('SOURCE_DB_USER')}:{os.getenv('SOURCE_DB_PASSWORD')}@{os.getenv('SOURCE_DB_HOST')}:{os.getenv('SOURCE_DB_PORT')}/{os.getenv('SOURCE_DB_NAME')}?charset=utf8"
        
        # Snowflake connection
        self.sf_params = {
            'account': os.getenv('SNOWFLAKE_ACCOUNT'),
            'user': os.getenv('SNOWFLAKE_USER'),
            'password': os.getenv('SNOWFLAKE_PASSWORD'),
            'role': os.getenv('SNOWFLAKE_ROLE'),
            'warehouse': os.getenv('SNOWFLAKE_WAREHOUSE'),
            'database': 'EYECARE_ANALYTICS',
            'schema': 'RAW'
        }
    
    def migrate_critical_tables(self):
        """Migrate all critical tables"""
        console.print(Panel("üéØ Migrating Critical Eyecare Tables", style="bold green"))
        
        # Create connections
        source_engine = create_engine(self.source_conn_str)
        sf_conn = snowflake.connector.connect(**self.sf_params)
        
        results = {
            'successful': [],
            'failed': [],
            'total_rows': 0
        }
        
        try:
            with Progress(
                SpinnerColumn(),
                TextColumn("[progress.description]{task.description}"),
                BarColumn(),
                console=console
            ) as progress:
                
                task = progress.add_task("Migrating critical tables...", total=len(self.critical_tables))
                
                for original_name, actual_table_name in self.critical_tables.items():
                    progress.update(task, description=f"[cyan]Migrating {actual_table_name}")
                    
                    try:
                        # Migrate single table
                        rows_migrated = self._migrate_single_table(
                            source_engine, sf_conn, actual_table_name, original_name
                        )
                        
                        results['successful'].append({
                            'original_name': original_name,
                            'actual_table': actual_table_name,
                            'rows': rows_migrated
                        })
                        results['total_rows'] += rows_migrated
                        
                        console.print(f"‚úÖ {original_name} ({actual_table_name}): {rows_migrated:,} rows", style="green")
                        
                    except Exception as e:
                        results['failed'].append({
                            'original_name': original_name,
                            'actual_table': actual_table_name,
                            'error': str(e)
                        })
                        console.print(f"‚ùå {original_name} ({actual_table_name}): {str(e)[:100]}...", style="red")
                    
                    progress.advance(task)
        
        finally:
            source_engine.dispose()
            sf_conn.close()
        
        # Display results
        self._display_results(results)
        return results
    
    def _migrate_single_table(self, source_engine, sf_conn, actual_table_name: str, original_name: str) -> int:
        """Migrate a single table using the actual table name"""
        
        # Step 1: Check if table exists and get sample data
        with source_engine.connect() as conn:
            try:
                # First, check if table exists
                check_query = f"""
                SELECT COUNT(*) as table_count
                FROM INFORMATION_SCHEMA.TABLES 
                WHERE TABLE_SCHEMA = 'dbo' AND TABLE_NAME = '{actual_table_name}'
                """
                
                check_result = pd.read_sql(check_query, conn)
                
                if check_result.iloc[0]['table_count'] == 0:
                    raise Exception(f"Table dbo.{actual_table_name} does not exist")
                
                # Get table structure
                columns_query = f"""
                SELECT COLUMN_NAME, DATA_TYPE, IS_NULLABLE
                FROM INFORMATION_SCHEMA.COLUMNS 
                WHERE TABLE_SCHEMA = 'dbo' AND TABLE_NAME = '{actual_table_name}'
                ORDER BY ORDINAL_POSITION
                """
                
                columns_df = pd.read_sql(columns_query, conn)
                
                if columns_df.empty:
                    raise Exception(f"No columns found for table {actual_table_name}")
                
                # Get row count first
                count_query = f"SELECT COUNT(*) as row_count FROM dbo.{actual_table_name}"
                count_result = pd.read_sql(count_query, conn)
                total_rows = count_result.iloc[0]['row_count']
                
                # Extract data with limit for safety
                limit = min(total_rows, 10000)  # Limit to 10K rows for safety
                
                data_query = f"SELECT TOP {limit} * FROM dbo.{actual_table_name}"
                df = pd.read_sql(data_query, conn)
                
                console.print(f"üìä {actual_table_name}: {total_rows:,} total rows, extracting {len(df):,} rows")
                
            except Exception as e:
                raise Exception(f"Could not read table dbo.{actual_table_name}: {str(e)}")
        
        # Step 2: Clean data for Snowflake
        if not df.empty:
            df = self._clean_dataframe(df)
        
        # Step 3: Create table in Snowflake
        sf_table_name = f"DBO_{original_name}".upper()
        
        cursor = sf_conn.cursor()
        try:
            # Drop and recreate table
            cursor.execute(f"DROP TABLE IF EXISTS EYECARE_ANALYTICS.RAW.{sf_table_name}")
            
            # Create table with simple VARCHAR columns for reliability
            columns = [f'"{col}" VARCHAR(16777216)' for col in df.columns]
            create_sql = f"""
            CREATE TABLE EYECARE_ANALYTICS.RAW.{sf_table_name} (
                {', '.join(columns)}
            )
            """
            cursor.execute(create_sql)
            
            # Step 4: Insert data
            if not df.empty:
                return self._insert_data_batch(cursor, sf_table_name, df)
            else:
                return 0
                
        finally:
            cursor.close()
    
    def _clean_dataframe(self, df: pd.DataFrame) -> pd.DataFrame:
        """Clean DataFrame for Snowflake"""
        # Convert all columns to string and handle nulls
        for col in df.columns:
            df[col] = df[col].astype(str)
            df[col] = df[col].replace('nan', '')
            df[col] = df[col].replace('None', '')
            df[col] = df[col].replace('NaT', '')
            df[col] = df[col].fillna('')
            # Remove problematic characters
            df[col] = df[col].str.replace("'", "''")  # Escape single quotes
            df[col] = df[col].str.replace('\n', ' ')  # Replace newlines
            df[col] = df[col].str.replace('\r', ' ')  # Replace carriage returns
        
        return df
    
    def _insert_data_batch(self, cursor, table_name: str, df: pd.DataFrame) -> int:
        """Insert data using optimized batch INSERT"""
        if df.empty:
            return 0
        
        # Prepare column names
        columns = [f'"{col}"' for col in df.columns]
        columns_str = ', '.join(columns)
        
        # Insert in larger batches for efficiency
        batch_size = 500
        total_inserted = 0
        
        for i in range(0, len(df), batch_size):
            batch = df.iloc[i:i+batch_size]
            
            try:
                # Prepare VALUES for batch
                values_list = []
                for _, row in batch.iterrows():
                    values = [f"'{str(val)}'" for val in row]
                    values_list.append(f"({', '.join(values)})")
                
                # Execute batch INSERT
                values_str = ', '.join(values_list)
                insert_sql = f"""
                INSERT INTO EYECARE_ANALYTICS.RAW.{table_name} ({columns_str})
                VALUES {values_str}
                """
                
                cursor.execute(insert_sql)
                total_inserted += len(batch)
                
            except Exception as e:
                console.print(f"‚ö†Ô∏è Batch {i//batch_size + 1} failed: {str(e)[:100]}...", style="yellow")
                # Try inserting rows individually for this batch
                for _, row in batch.iterrows():
                    try:
                        values = [f"'{str(val)}'" for val in row]
                        values_str = ', '.join(values)
                        single_insert_sql = f"""
                        INSERT INTO EYECARE_ANALYTICS.RAW.{table_name} ({columns_str})
                        VALUES ({values_str})
                        """
                        cursor.execute(single_insert_sql)
                        total_inserted += 1
                    except:
                        continue  # Skip problematic rows
        
        return total_inserted
    
    def _display_results(self, results: dict):
        """Display migration results"""
        
        # Success table
        if results['successful']:
            success_table = Table(title="‚úÖ Critical Tables Successfully Migrated")
            success_table.add_column("Original Name", style="cyan")
            success_table.add_column("Actual Table", style="blue")
            success_table.add_column("Rows Migrated", style="green")
            
            for item in results['successful']:
                success_table.add_row(
                    item['original_name'], 
                    item['actual_table'],
                    f"{item['rows']:,}"
                )
            
            console.print(success_table)
        
        # Summary
        total_tables = len(results['successful']) + len(results['failed'])
        success_rate = (len(results['successful']) / total_tables * 100) if total_tables > 0 else 0
        
        summary_table = Table(title="üìä Critical Tables Migration Summary")
        summary_table.add_column("Metric", style="cyan")
        summary_table.add_column("Value", style="green")
        
        summary_table.add_row("Total Critical Tables", str(total_tables))
        summary_table.add_row("Successfully Migrated", str(len(results['successful'])))
        summary_table.add_row("Failed", str(len(results['failed'])))
        summary_table.add_row("Success Rate", f"{success_rate:.1f}%")
        summary_table.add_row("Total Rows Added", f"{results['total_rows']:,}")
        
        console.print(summary_table)
        
        # Show failures
        if results['failed']:
            console.print(Panel("‚ùå Failed Critical Tables", style="red"))
            for item in results['failed'][:3]:
                console.print(f"  {item['original_name']} ({item['actual_table']}): {item['error'][:100]}...", style="red")

def main():
    """Main execution"""
    console.print(Panel("üéØ Critical Eyecare Tables Migration", style="bold green"))
    
    try:
        migration = CriticalTableMigration()
        results = migration.migrate_critical_tables()
        
        console.print(Panel(
            f"üéâ Critical Tables Migration Complete!\n\n"
            f"‚Ä¢ Tables Migrated: {len(results['successful'])}\n"
            f"‚Ä¢ Total Rows Added: {results['total_rows']:,}\n"
            f"‚Ä¢ Your critical eyecare data is now in Snowflake! ‚úÖ\n"
            f"‚Ä¢ Combined with previous migration: Complete eyecare analytics ready!",
            style="bold green"
        ))
        
    except Exception as e:
        console.print(f"‚ùå Critical tables migration failed: {str(e)}", style="bold red")

if __name__ == "__main__":
    main()
